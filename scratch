Old Metaprogramming API

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////

Workspace_Open :: proc(workspace: ^Workspace, options: Workspace_Options, file_path: String) -> bool ---;

Workspace_Close :: proc(workspace: Workspace) ---;

Workspace_InspectNextDeclaration :: proc(workspace: Workspace, declaration: ^Declaration) -> bool ---;

Workspace_ModifyCurrentDeclaration :: proc(workspace: Workspace, declaration: ^Declaration) -> bool ---;

Workspace_InjectDeclaration :: proc(workspace: Workspace, package: string, declaration: ^Declaration) -> bool ---;

Workspace_InjectImport :: proc(workspace: Workspace, package: string, path: string, alias: string) -> bool ---;

Workspace_GenerateBinary :: proc(workspace: Workspace, options: Binary_Options) -> bool ---;


// TODO:
  - Find out how types should be represented and manipulated in the metaprogram
  - Find out how the metaprogram should refer to declarations
  - Maybe ditch the direct declaration based API with a message loop instead?
  - Should the internal and API representation of the AST be memory compatible?
  - Should body_text and modify be a part of the language and how should they be handled?

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////


New Metaprogramming API

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////

OpenWorkspace

CloseWorkspace

FetchNextDeclaration

ResubmitDeclaration

EmitDeclaration

// CommitDeclaration -- implicit

NumDeclarationsLeft -- different name or function?

GenerateBinary


// TODO:
  - Find out how types should be represented and manipulated in the metaprogram. Build metaprogram local type table and use type infos
  - Should the internal and API representation of the AST be memory compatible? NO
  - Should body_text and modify be a part of the language and how should they be handled?

//////////////////////////////////////////////////////////////////////////////////////////////////////////////////

entities : []Declaration;

for (decl: ^Declaration; FetchNextDeclaration(workspace, &decl))
{
	if (decl.name == "main" && NumDeclarationsLeft(workspace) != 0) ResubmitDeclaration(workspace, decl);
	else
	{
		if (decl.kind == Declaration_Struct)
		{
			if (HasTag(decl, "entity"))
			{
				if (!HasTag(decl, "no_serialization")
				{
					serialization_proc := ParseCode(...); // create some sort of serialization procedure

					Submitdeclaration(workspace, serialization_proc);
				}

				append(&entities, decl);
			}
		}

		else if (decl.kind == Declaration_Proc)
		{
			// do something with types
		}

		if (NumDeclarationsLeft(workspace, "entity") == 0)
		{
			// do something with all the entities
		}
	}
}

// TODO(27.09.20):
Try to tame LLVM into producing good code for this example: https://www.youtube.com/watch?v=R5tBY9Zyw6o&t=29s,
and see if something can be done in the compiler to reduce this kind of confusion

Problems:

- What about two files who want to share the same local
  namespace, but cannot be part of the same file for
  some reason

- Pointer vs intervall (unbounded, increment)

- When should strings be resovled?

- Should there be a distinction between static arrays and intervals





CreateWindow :: proc(style: u32,
                     class_name: ^u8,
                     window_name: ^u8,
                     style: u32,
                     x: int, y: int,
                     width: int, height: int,
                     parent: ^WND,
                     menu: ^MENU,
                     instance: ^INSTANCE,
                     param: rawptr) -> (HWND, error)
                where class_name != 0, window_name != 0,
                      error is_in {Success, Not_Enough_Memory, Out_Of_Memory, Bad_Arguments}
{
	// impl
}

x is_in [N]T expands to x == [0] || x == [1] || x == [2] || ...

for (x in struct) expands to for (it, it_index : any, int = Iterate(struct); it.data != 0; Advance(&it, &it_index));

What the compiler has to do:
	Semantially check an AST
	Generate type and symbol tables
	Resolve identifiers
	Generate bytecode
	Run bytecode
	Generate IR


What if you want to compiler C code as Otus code?
	Write parser that emits Otus AST
	Run metaprogram that compiles the AST
Problems:
	How to tag code without the ability to use attributes?
	How to report checker errors with a foreign AST?
		Each AST node has an ID and a Text_Interval
		The error handler (which is the user has to implement) gets the node, ID and Text_Interval, along
		with any extra information about the problem




General problems:
	How should dynamic arrays work? (_NO_ boilerplate)


Start & stop compilation
Loop over every declaration
Decide whether to defer or handle a declaration immediately
Store declaration information
Modify declaration and recheck
Query about the remaining declarations
Decide how errors and warnings should be logged
Add additional AST nodes to the compilation





NOTE:
	There isn't much point in separating the parser from the compiler, since it does not help with support for other languages,
    since they have to be transpiled either way, and it does not do much for non textual editors.
	However, it may still be usefull to move the parser into the metaprogram, but still keep a text-centric handling of
	debug info and things related. One problem with parsing code in the metaprogram is that import and load declarations
	cannot be handled as done previously.

API for separated parser:
	- Register package
	- Add ast to package
	- Error handling has to be implemented by the metaprogram
Problems:
	- What about name lookup rules? Should they be ruled by the compiler or metaprogram?

Metaprorgamming should support:
	- Custom name lookup rules
	- Full introspection




Problems:
	- context and allocation
	- error handling semantics
	- attributes, directives and keywords
	- control structures
	- Type, ABI, name lookup and other non AST metaprogramming features
	- Overload picking, type resolution

Stages:
	* Parse
	- Check and modify AST
	- Generate bytecode
	- Run bytecode
	- Analyse, optimize and check bytecode
	* Generate output


What could be metaprogrammed in each stage:
	- Checker
		type conversion
		//symbol lookup and modification (except constant decls)
		inference
		modify AST
		decide inliness
	- Bytecode gen
		Overload resolution - This has to be done after every declaration has been generated, but does not deserve its own stage
-	- Bytecode run
		//what and in which order bytecode should run
	- Analyse and optimize
		perform arbitrary analysis and changes to bytecode

The metaprogram performs general transformations
The source code performs special transformations and specifies restrictions to the metaprogram

Problem: Should these be metaprogrammable?
	- symbol lookup
	- type checking
	- overload resolution

Solution:
	There are only four cases where being able to metaprogram these is usefull
		- on/off name shadowing
		- custom implicit conversions
		- polymorphism solving
		- overload resolution
	
	Polymorphism solving should be done by the compiler, since the only thing that is worth changing
	is whether matching based on return value should be allowed or not.

	Custom implicit conversions is only useful
	when compiling code from other languages, and since overload resolution, symbol lookup and type checking needs to
	be done by a trnaspiler to conform to this languages' AST and rules, it is not much additional work to handle
	implicit conversions in th e transpiler instead.
	The same reasoning applies to name shadowing.

	Since there are no custom implicit conversions and polymorphism solving, there is also no need for custom overload
	resolution

// Updated

What could be metaprogrammed in each stage:
	- Meta
		modify AST
		decide inliness
	- Analyse and optimize
		perform arbitrary analysis and changes to bytecode

What could be changed about a declaration (-: can change, *: cannot change):
	- body
	* procedure header (due to possible dependencies on procedures, that depend on the current procedure, within the proc body)
	- scope apperance (add to scopes)

The metaprogram performs general transformations
The source code performs special transformations and specifies restrictions to the metaprogram

Metaprogram API
Open Workspace  - provide AST and options for compilation
Close Workspace - Free resources

Language constructs

AST


Problems:
	- how to handle scopes in the metaprogram?
	- Where should non-global declarations be stored, and should they be treated as global declarations by the metaprogram?
	- How should overloads be handled? Implicit overloads may lead to a lot of halting, but explicit overloads will limit
	  injection
	- custom parser, what about compiler directives?
	- ^void or rawptr
Todo:
	- rename for to while and change for to for each


Compiler directives: * is handled by the compiler before meta
	- bake & maybe dynamic bake *
	- body_text *
	- assert
	- scope_inject *
	- run
The metaprogram needs to be able to emit these, should they therefore be a part of the AST, maybe?

//////////////////////


///////////////////////
      CONTRACTS
///////////////////////

// old
proc -> (i: int) where i >= -1 && i <= i32_max { return random_int(-1, i32_max); };

// maybe
RandomN1Max :: inline proc(max: $T, random_int : proc(T, T) -> T) -> (i: T)
			   #contract_overload(is_integral(T)),
			   #contract_in(max >= 0 && random_int(0, 0) == 0),
               #contract_out(i >= -1 && i <= i32_max)
{
	return random_int(-1, i32_max);
};

MemoryArena_AllocateSize :: proc(arena: ^Memory_Arena, size: uint, alignment: uint = 1) -> (memory: ^void)
							#contract_in(arena != 0 && size != 0 && alingment != 0),
							#contract_out(memory != 0)
{
	memory = malloc(size + alingment - 1);
}

// maybe
RandomN1Max :: inline proc(max: int, random_int : proc(int, int) -> int) -> (i: int)
                      contract = {
                          in  = max >= 0 && random_int(0, 0) == 0,
                          out = i >= -1 && i <= i32_max
                      }
{
	return random_int(-1, i32_max);
};

SomeContract :: contract(max: int, i: int) {
    in:  max >= 0 && random_int(0, 0) == 0,
    out: i >= -1 && i <= i32_max
};

RandomN1Max :: inline proc(max: int, random_int : proc(int, int) -> int) -> (i: int)
                      contract = SomeContract(max, i) + {in: max < 5}
{
	return random_int(-1, i32_max);
};

compose
standardize / attach to types
in, out, overload

RandomN1Max :: inline proc(max: $T, random_int : proc(T, T) -> T) -> (i: T)
                      contract = {
					      overload: is_integral(T)
					      in: max > -1 && random_int(0, 0) == 0
					      out: i >= -1 && i <= T.max
					  }
{
	return random_int(-1, i32_max);
}

MemoryArena_AllocateInt :: proc(arena: ^Memory_Arena, $type: typeid) -> (memory: ^void, err: error)
						contract(overload, is_integral(type) && sizeof(type) != 0 && alignof(type) != 0),
						contract(in, arena != 0),
						contract(out, memory != 0 && (err == .OutOfMemory || err == .InvalidArena)),
{
}

OpenFile :: proc($file_name: string, open_mode: enum { Read, Write, ReadWrite }) -> File_Handle
			where file_name.size != 0, ValidatePath(file_name),
{

}

restrict overloading              - where clause
restrict errors                   - metaprogram
restrict argument & return values - metaprogram
error handling                    - return error codes

// maybe use an error type?
//////////////////////////////////////////////////////////////////////////////////

error type
error :: struct(kind_t: typeid, data_t: typeid)
         where typeinfo_of(typeid).kind == Type_Info.Enum
{
	kind: kind_t,
	data: data_t
}

if (err) success is _always_ 0

return err = {.OutOfMemory, "The program is out of memory"}

Contracts can be implemented with a metaprogram

@contract("in", array != 0 && typeid_of(T) != 0)
@contract("out", err in {.Success, .OutOfMemory, .InvalidArguments})]
@link_name("append_by_value")
@NoProfile
append_by_value :: proc(array: ^$T/^[..]$S, elem: S) -> (err: error)
				   where typeinfo_of(T).kind != Type_Info.Array
{
	if (err := grow(array); err) return err;
	array[array.size - 1] = elem;

	return .Success;
}

@[
  contract("in", array != 0 && typeid_of(T) != 0),
  contract("out", err in {.Success, .OutOfMemory, .InvalidArguments})],
  link_name("append_by_value"),
  NoProfile
]
append_by_value :: proc(array: ^$T/^[..]$S, elem: S) -> (err: error)
				   where typeinfo_of(T).kind != Type_Info.Array
{
	if (err := grow(array); err) return err;
	array[array.size - 1] = elem;

	return .Success;
}

//////////////////////////////////////////////////////////////////////////////////

// Array.os

append_by_value :: proc(array: ^$T/^[..]$S, elem: S) -> error
{
	if (err := grow(array); err) return err;
	array[array.size - 1] = elem;

	return .Success;
}

append_by_ptr :: proc(array: ^$T/^[..]$S, elem: ^S) -> error
{
	return append(array, *S);
}

append :: proc[append_by_value, append_by_ptr];

// main.os

import "Array.os" as array;

append_by_any_value :: proc(array: ^$T/^[..]$S, elems: ..S) -> error
{
	for (elem in elems)
	{
		err := append(array, elem);

		if (err) return err;
		else continue;
	}

	return .Success;
}

#inject(append_by_any_value, array.append);

///////////////////////
 RENAMING DECLARATIONS
///////////////////////

#scope_file
import "NintendoCode" as Nintendo;
#scope_export

#insert {
	code : Code;

	instert_if_statement(askdaslkdalskdlaksdlkasdl);
	{
		nintendo_info := typeinfo_of(Nintendo);
		assert(nintendo_info.kind == Type_Info.Package);

		for (declaration in nintendo_info.declaration)
		{
			new_decl := declaration;
			new_decl.name = concatenate_strings("NC_", declaration.name);

			append(&code.declarations, new_decl);

			context->free(new_name.data);
		}
	}

	return code;
}

list over what the metaprogram _can_ do (everything that does not break resolved declarations, and is also sane):
	- add ~~& remove~~ declarations
	- resubmit declarations
	- commit declarations

	- inspect pending declarations
	- inspect finished declarations
	- inspect type table
	- inspect symbol table

//	- change declaration name
//	- change parameter names
	- change declaration body (value in case of constant or variable)

	- add procedures to groups
	- add procedures to groups which have "finished compilation"
	- add additional scope links to declaration

list over what the metaprogram _cannot_ do (everything that breaks resolved decls or is insane):
	- remove declarations
	- remove procedures from groups
	- remove declaration from scopes

	- change top declaration type
	- change declaration name
	- change structure header
	- change procedure header
	- change symbol or type table
	- change symbol lookup or overload resolution rules
	- change type checking rules

problems regarding this:
	- How should scope_file be represented and handled in the metaprogram?


29.09 Notes:
	- addition and removal of struct members can be done assuming structs are prioitized by the checker
//	- procedure parameter names can be changed by introducing the concept of aliasing, and either making
//	  the cannonical form for non-positional arguments indeces, or sorting the arguments and filling in
//	  blanks explicitly with the default value
//	- declaration names can be changed by introducing the concept of aliasing and making the cannonical form
//	  for symbols a UUID instead of a string
	- procedures that contain calls to overloaded procedures should be held at an intermediary stage between
	  the metaprogram and bytecode generation until they can be unambiguosly resolved
//	- removal of declarations can be supported by introducing an intermediary stage between the type checker and
//	  metaprogram where procedure headers are held until their body arrives. This allows for declaration removal
//	  without breaking any resolved references
//	- pointer to const is useful
	- steps in slices can be achieved by a mapping procedure

29.09 Problems:
	- context and allocators
	- the for loop and iterators
	- "struct overloading/specialization"

Problems:
	- parameter default value cannot be changed without having to introduce some sort of dependency tracking

Reasons for not allowing modification of parameter names
	- breaks references in the AST while the metaprogram is operating on it
	- introduces "weird edge cases" where parameter name can be modified, but not type of default value
	- behaviour can easily be replicated with a procedure binding

Reasons for not allowing modification of declaration names:
	- disconnect between symbols in source code and resulting bytecode and binary
	- behaviour can easily be replicated with an "alias declaration"

Reasons for not allowing declaration removal
	- declaration removal can break semi-resolved refences and requires a lot of machinery to
	  keep sane

Reasons for not implementing a "pointer to const" concept:
	- cannot be enforced due to pointer aliasing, and is therefore sort of pointless


__Array_Normal :: struct(T: typeid, S: typeid = uint)
		          where typeinfo_of(S).kind == Type_Info.Integer &&
                        (cast(^Type_Info_Integer) typeinfo_of(S)).is_signed == false
{
	data: ^T,
	size: S,
	capacity: S,
	allocator: Allocator
}

__Array :: struct[__Array_Normal];


inject __Array <- struct(T: typeid, bucketed: bool, bucket_size: uint = 10)
					     where bucketed == true
{
	first:   ^void,
	current: ^void,
	current_size: uint,
}


__Array :: struct(T: typeid)
{
	allocator: ^Allocator,
	data: ^T,
	size: uint,
	capacity: uint
}

Intergal_Type_Array :: struct(T: typeid) where (T 'CanBeUpcastedTo' int)
{
	allocator: ^Allocator,
	data: ^T,
	size: uint,
	capacity: uint
}


The import system is now centered around the concept of a module. A program consists of a single source file that may
	 "import" and "load" modules and source files. Loading a source file is effectively the same as copy/pasting the source
	 code, but with added semantic information. Meaning, a file that loads five other files can effectively be thought of
	 as one large file containing all 6 files. Duplicate and cyclic loads are therefore illegal. Importing a module is quite
	 different from loading a file. Modules are collections of source files that share the same namespace and link name
     prefix, if not overridden. Additionally, every module may include a possibly unique metaprogram. Importing a module
     will create a link from the importee's namespace to the module's namespace, represented as a symbol with a name equal
     to the module name. When a module is imported for the first time, it's metaprogram is ran and the resulting information
     is cached. Every subsequent import from any module will refer to that very same cached information. It is also possible
     to instantiate a different version of the module that may have a different name and provide arbitrary arguments to the
     module's metaprogram. Multiple imports of the same module with different names are allowed, but multiple imports under
     the same name are not. Cyclic imports are also allowed, since an import is only a link to a namespace. Loads require a
	 file path in the format "prefix:path/to/file_with_optional_extension", while imports require a path to either a directory
	 or file, in the format "prefix:path/to/file_or_directory_with_optional_extension". The "prefix:" part is optional, and is
	 used for absolute paths (file paths are normally relative). Addition and removal of prefixes can be done in a metaprogram.
	 Importing a directory will import a file within that directory of the same name and the correct extension. Additionally
	 there is "foreign import" which import c style dynamic libraries.




Decissions:
- Modules do not posses their own metaprogram
- Modules renamed to packages (since they now are just a bunch of source files)
- Import aliasing only affects the symbol name for the importer
- The metaprogram decides things about the package before it is processed (like import overriding)
- Imports are not exported from packages, unless they are explicitly exported
- using imports are scope local
- custom parsing will not be supported in the near future



using import "core:math" as Math; //Math, math
using import "core:math"; //-,math
import "core:math"; // math
import "core:math" as _;
using import "core:math";

using symbol as new_symol;

using Math.cos as cos;
using math as Math;


injection
replacement

package main

import "";
#include("");
#load("")


C tricks

// brace init everywhere
struct Struct { int member; };
Struct s;
s = (struct Struct){.member = 0}; // valid

// using
struct Child
{
    struct Struct; // equivalent to using
};

Child c = {.member = 0};

// pointer to temporary
in c you can always do (int[]){{3}} which is more portable than &(int){3}


Attribute - @name(param0, param1)
Directive - #name

[attribute] statement
[directive] expr

[attribute] Name :: [directive] struct([attribute] [directive] name: [directive] type, ) where [directive] expr [attribute]
{
	[directive] name: [directive] type [attribute],
}

[attribute]
Name :: [directive] enum [directive] type
{
	[directive] name = [directive] value [attribute],
}

[attribute] Name :: [directive] proc([attribute] [directive] name: [directive] type, ) -> ([attribute] name: [directive] type, ) where [directive] expr [attribute] {}


Package system, syntax, type rules and AST format is core to the language
everything else is custom

The reason for the package system being core, and not custom, is to ensure different code bases have a well defined interface










																	TODO: Should 'attributes' be used to markup expressions?
                                                                          What about compiler directives?


if      (StringCompare(token.string, CONST_STRING("include"))) directive->kind = Directive_Include;
        else if (StringCompare(token.string, CONST_STRING("load")))    directive->kind = Directive_Load;
        else if (StringCompare(token.string, CONST_STRING("code")))    directive->kind = Directive_Code;
        else if (StringCompare(token.string, CONST_STRING("insert")))  directive->kind = Directive_Insert;
        else if (StringCompare(token.string, CONST_STRING("run")))     directive->kind = Directive_Run;
        else if (StringCompare(token.string, CONST_STRING("bake")))    directive->kind = Directive_Bake;


@attribute(1 + 2);

** Solution #1: Whitespace matters (@attribute(1 + 2); != @attribute (1 + 2);)
Solution #2: No arguments
Solution #3: Wierd braces, brackets or parens



Correction after metaprogram parse
  - should sema be run?
  - should the correction be visible to the metaprogram?

Debug info
  - need existing/generated text + info about origin
  - how to handle interleaved existing and generated when it comes to the generated text?

Type checking
  - How free should custom type checking be?

When statements needs to be resolved before complete type checking
Finished programs only have a notion of symbol info, data and procedures

Parsed statements -> Meta -> Committed Declarations -> Bytecode
*** The metaprogram can only commit declarations* ***
  - can only commit constant and variable declarations


structs ----- This is metaprogram stuff, can easily be changed in the symbol table after type checking
 - ordered
 - packed
 - alignment

calling convention -
inlining           - must support force inline/no_inline of bytecode
loop unrolling     - probably better to do after bytecode gen
intrinsics         - provide procedures to fall back on, handle when translating bytecode, maybe?



The context system is core to the language
There are two main calling conventions: context and context-less
Foreign procedures support any c calling convention

Bytecode is a metaprogram level concept
 - The compiler only understands AST, symbol info, symbol info gen and text -> AST transformations
 - The bytecode can only change values in the AST

To produce a binary the AST is used NOT the bytecode
Start with generating C code from AST, maybe custom backend later




Open -> Parse -> Check -> Modify -> Commit ----------> Close
         ^        ^ Recheck |              |          ^
		 |        |---------<              v          |
         |    AddNewDecl    |                Generate
		 -------------------<

Statement #1: The language's rules apply in the parsing and commit stage. The modify and check stage is free to do whatever
Statement #2: The generate stage is optional
Statement #3: The compiler-side parser remains focused on parsing files, the metaprogram-side parser will be used for smaller tasks

Question #1: Should the metaprogram __change__ the ast, or just inspect it and apply textual diffs?
Question #2: How to deal with interleaved source and generated code when adding debug info?
Question #3: If the metaprogram modifies the AST with text, should the text be parsed, or parsed and checked?
Question #4: Should the calling convention (context/context-less) be decided by whether the context is used or not?
Question #5: How to handle polymorphic declarations? Should the metaprogram be responsible for instantiation?

SerializeEntity :: proc(entity: $T)
@body_text {
	type_info := type_info_of(T);
	assert(type_info.kind == .Struct);

	b: String_Builder;

	for field, index in type_info.structure.fields
	{
		tprint(b, "\nprint(%: %%);", field.name, field.value, (index != type_info.structure.fields.size - 1 ? '\n' : ''));
	}

	return FinalizeString(b);
}


--- Question #5: How to handle polymorphic declarations? Should the metaprogram be responsible for instantiation? ---
Polymorphism is core to the language, meaning the compiler should handle it. There should be a default solver in the
default type checking procedure, and generation of specialized declarations should be handled by the compiler.
Specializations are generated on demand and added to the "statement pile"

for loop syntax

Proposed syntax: for symbol_0, symbol_1, symbol_2 in iterator body
Problems:
  - No ability to specify types explicitly
  - Use of keyword 'in' but not the 'in' operator


Todo
 - Generate missing symbol info from partial declaration
 - Symbol id that can reference both symbols in scope chain and package tables

What happens to package symbol entry when
 a decl is checked out?
What about the type info from proc headers?

Parser problems
 - Should package declarations be a thing?

What to do about error handling in the meta program?


			When should compound expressions be collapsed?



String :: proc -> typeid do return struct { data: ^u8, length: int };

// these statements are tautologies
struct { data: ^u8, length: int } == struct { data: ^u8, length: int }
struct { data: ^u8, length: int } != struct { dat: ^u8, length: int }
struct { data: ^u8, length: int } != Struct()
is_memory_compatible(struct { data: ^u8, length: int }, Struct())

a: Struct();
b: Struct();

typeid_of(a) == typeid_of(b)

Array :: proc(N: int) -> typeid do return struct { a: [N]int };

// these statements are tautologies
struct { a: [10]int } == struct { a: [10]int }
struct { a: [10]int } != struct { a: [9]int  }
struct { a: [10]int } != struct { b: [10]int }
struct { a: [10]int } != Array(10)
is_memory_compatible(struct { a: [10]int }, Array(10))

a: Array(10);
b: Array(10);
c: Array(9);

// these statements are tautologies
typeid_of(a) == typeid_of(b)
typeid_of(a) != typeid_of(c)


for m: 1..4 do print(m);                     // 1234

for m in 1..4 do print(m);                   // 1234

while m := 1; m in 1..4; m += 1 do print(m); // 1234

if m := 1; m in 1..4 do print(m);            // true

------------------------------------------------
     Attribute and directive redesign
------------------------------------------------

Advantages with old design
- no ambiguities between whether a "note" belongs to an expression or statement

Disadvantages with old design
- not clear why it is necessary to distinguish between "notes" that attach to statements, and "notes" that attach to expressions
- introduced some whitespace hacks in the lexer
- one more thing to keep track of in the AST, which complicates the entire system

Proposal:
ditch user specified #directives and rely only on @notes

This has some clear advantages
- more control is given to the compiler, as #run, #code, #source_location can now be implemented in the language and handled by the compiler, instead of the default meta program
- cleaner syntax @ declares a note for the meta program, while # is a note for the compiler
- allows for the possible introduction of #body_text without changing struct and enum syntax

But is also introduces some ambiguities
- @attribute0 @attribute1 expression = expression; // is attribute0 & -1 attached to the assignment or the lhs expression?

#load - load file and return []u8

// remove using as, replace with using¨
// what to do about character literals? ' or ` ?

source_location
caller_location
packed
padded
ordered
unordered
code_block{}
run
insert
import
load
foreign
inject
distinct


Is there a way to make "for a in b do x;" a macro?

------------------------------------------------
            Metaprogramming API
------------------------------------------------

To limit complexity:
 - No custom parsing. If a user wants custom parsing, they can implement the parser themselves and pass the AST to a
   metaprogram.
 - No rechecking of declarations. If a declaration is checked and committed as finished, it cannot be changed.

The metaprogram opens a workspace, which initializes the compiler. If a main file is supplied during this initialization, it, and all its dependencies, are parsed. The metaprogram is ten able to access these parsed declarations, process them, and commit any declaration (parsed by the compiler or created by the metaprogam). When a declaration is committed, it is type checked by the compiler and is then available for type and symbol queries. When the metaprogram decides to stop committing declarations, it can ask the compiler to build a binary from the committed declarations.

A workspace is a struct containing state that is exposed from the compiler about the current "compilation"

Open
Close
Query*
CommitDeclaration
BuildBinary

Idea:
 - errors are written to a buffer in the workspace
 - Commit, Build and Open only return whether an error has occurred, or not

Procedure :: proc -> (a: int, b: int) do return 0, 0;

x := Procedure(); // Should this be legal? Should x become a []any?

x := Procedure()[1]; // Should something like this be possible?
x := Procedure().b; // Or maybe this?

a, b, _, d = Procedure();

How to deal with import "../" and load "./file.os" in "file.os"?



------------------------------------------------
			Interval syntax
------------------------------------------------

[a, b]            /**/   a..b
[a, b)            /**/   a..<b
(a, b]            /**/   -----
(a, b)            /**/   -----
/**/              /**/
for i in [a, b]   /**/   for i in a..b
for i in [a, b)   /**/   for i in a..<b
for i in (a, b]   /**/   --------------
for i in (a, b)   /**/   --------------
/**/              /**/
[, b]             /**/   ..b
[, b)             /**/   ..<b
(, b]             /**/   -----
(, b)             /**/   -----
/**/              /**/
for i in [, b]    /**/   for i in ..b
for i in [, b)    /**/   for i in ..<b
for i in (, b]    /**/   --------------
for i in (, b)    /**/   --------------
/**/              /**/
[a, ]             /**/   a..
[a, )             /**/   a..<
(a, ]             /**/   -----
(a, )             /**/   -----
/**/              /**/
for i in [a, ]    /**/   for i in a..
for i in [a, )    /**/   for i in a..<
for i in (a, ]    /**/   --------------
for i in (a, )    /**/   --------------

Goals for syntax and semantics redesign
 * preserve the feeling of C
 * stay close to the syntax of Jai and Odin
 * remove all ambiguities that cannot be sanely resolved later down the pipeline
 * raise higher level abstractions to the metaprogram, unless it results in clunky
   syntax for syntax for something that is often used

To be decided today (hopefully):
 * syntax
 * should name shadowing be allowed?
   - only procedures may shadow
 * how should overloading work?
   - implicit, late additions are warned, countermeasure is to declare earlier
 * how should metaprograms work with libraries?
 * what should be done with local procedures? Should they be taken out of their parent and sent throught the pipeline
   separately?

Basics:
 * the type should come after the name
 - this is essentially to allow types to exist in one place, instead of being applied
   to different sides of a name (like arrays in C). Whether they come before or after
   is largely up to taste. However, if the type comes after the name, instead of before,
   is is more consistent with existing languages.
 * types are read left to right
 - as in pointer_symbol int, is read as pointer to int, and array_symbol pointer_symbol int,
   is read as array of pointers to ints.

Opinions:
 * I don't want name shadowing in the language. However, this introduces some problems
   with both overloads, and there might be someone who wants to support name shadowing.
   It is easier to disallow name shadowing than to allow it, so maybe it should be
   allowed. I can personally then just disallow shadowing in my metaprograms. It has
   also been pointed out that the := syntax combined with variable name shadowing is
   somewhat bug prone.

Ideas:
 * a solution to the overloading problem, at least when it comes to symbol linking, could be
   to state that all overloads must be registered before any of them are bound to calls. An
   overload registered after any of the previous overloads are used will then throw an error.
   The problem with this is: what happens with local procedures that overload global procs, or
   even other local procs?

Remarks:
 * I don't want to give up all the custom metaprogramming just because I'm making a library


Problem: the result of struct { x: int } == struct { x: int } cannot be decided by the metaprogram, when the compiler
         type checks at commit


Big decision:
Should all dedclarations passed to the metaprogram be type checked by the compiler?
 + This simplifies the metaprogram tremendously
 - But it also removes A LOT of freedom
 + It also simplifies the idea of metaprogramming, since the metaprogram is much more limited
 + Problems with symbols and overloading are much simpler
 + It allows greater control in the design of the language
 - Custom overloading, custom casting rules, set builder syntax (e.g. {r in u32: r > 3}), and much
   more is now impossible

What about passing only semantically valid declarations with symbols generated and types resolved?
 + This allows custom casting rules and set builder syntax, but not statements that are not declarations
   in the global scope

What about passing only semantically valid declarations with symbols generated and types resolved, but this
   is implemented in the metaprogram layer?
 + supports common use case and allows for full control if wanted

Decided: Only type checked declarations are passed to the metaprogram. The metaprogram is now considered as an intecepter in
         the compilation process, instead of being in charge of every operation. This is to make it possible for me to
         finish this compiler within the next decade.

Overloading: implicit vs. explicit
implicit:
 + low friction when adding or removing overloads
 + allows use of common names (like iterate)
 - unclear which procedure a name is resolved to
 - problematic when it comes to metaprogramming, since adding a new procedure could invalidate already compiled code,
   if it is a better match
explicit:
 + clearer what is overloaded, and what is not
 + clearer what a procedure name can be resolved to
 - more friction, both by requiring unique procedure names everywhere, and updating procedure groups, but also when dealing with overloaded procedures in a library (removes the ability to supply overloads to the library)
 - common procedure names (like iterate) is a pain, since it could be defined in a library

Implicit seems to be the way to go, since it is a lot easier to use, and the problems with it could be solved by
supplying better debug info and solving the problem with program invalidation on late additions in the metaprogram.

Solutions to program invalidation on late (after use/resolution of a name) addition of overloads
 1. disallow addition after use
 2. keep track of users, check on addition if it invalidates previous uses, error if this is the case
    (the reason for throwing an error is that that procedure may have been run already)
 3. only warn on late addition
 4. require late additions to be declared earlier

PS: declaring, in source, a procedure that is known to be a late addition, but not defining its body, can remove all of these
    problems

1 is a bit limiting
2 seems like too much trouble
3 seems reasonable, since late additions may not lead to an invalid program, per se, but it often could.
4 seems like too much trouble

Name shadowing: yay or nay?
Requiring no shadowing for procedures when overloading is implicit seems stupid, but allowing everything to shadow seems
equally stupid.
Why not just disallow it for everything but procedures. I need to finish this compiler soon, and that is not happening if I
try to please everyone. Personally I think variable shadowing is stupid, and since I don't use libraries, name collisions have
never been a major problem for me.
However, that means a procedure bound to a name is fundamentally different from a struct bound to a name. Should this be shown
with a syntax difference? Jai and Odin does not do this, but both have some sort of shadowing. Nah, I think it is acceptable to
just state that only constants bound to procedures with a body may shadow.

What should the pointer type symbol be?

Option #1
a: ^type = &value;

Option #2
a: &type = &value;

option #2 causes problems with typeid, since it is ambiguous whether one wants to take an address to the typeid, or take the
pointer type... Which actually may be a non problem, since taking the pointer type can only be done with constants, and
it is kind of wierd to take the address of a constant. Maybe the default bahaviour should be to take the address of if it
is a variable and pointer to if it is a constant? It kind of removes the ability to detect types and fix precedence in the parser thoug.
I think I will go with option #1


-------------------------------------------------------
                       Syntax
-------------------------------------------------------

keywords:
proc
struct
union
enum
where
when
if
else
while
break
continue
defer
using
return


name refers to an identifier, which is defined as _|(_*[a-zA-Z]+[a-zA-z\d]*)

// arguments
name: type = value
name: $type = value
$name: type = value
$name: $type = value

name0, name1   : type  = value
name0, name1   : $type = value
$name0, name1  : type  = value
name0, $name1  : type  = value
$name0, $name1 : type  = value
$name0, $name1 : $type = value

using name: type = value
using name: $type = value
using $name: type = value
using $name: $type = value

using name0, name1   : type  = value
using name0, name1   : $type = value
using $name0, name1  : type  = value
using name0, $name1  : type  = value
using $name0, $name1 : type  = value
using $name0, $name1 : $type = value

// variable declaration syntax
name : type = value;
name0, name1, name2 : type = value;
name0, name1, name2 : type = value0, value1, value2;

name : type = ---;
name0, name1, name2 : type = ---;

using name : type = value;
using name0, name1, name2 : type = value;
using name0, name1, name2 : type = value0, value1, value2;

using name : type = ---;
using name0, name1, name2 : type = ---;

// value can be --- to tell the compiler not to zero initialize the variable(s)

// constant declaration syntax (must be easy to distinguish procedures from structs and other constants)
name : type : value;
name0, name1, name2 : type : value;
name0, name1, name2 : type : value0, value1, value2;

using name : type : value;
using name0, name1, name2 : type : value;
using name0, name1, name2 : type : value0, value1, value2;

// value cannot be --- ?

// procedure type
proc
proc(args)
proc -> return_values
proc(args) -> return_values

// procedure definition
proc do statement
proc(args) do statement
proc -> return_values do statement
proc(args) -> return_values do statement

proc where expression do statement
proc(args) where expression do statement
proc -> return_values where expression do statement
proc(args) -> return_values where expression do statement

proc {}
proc(args) {}
proc -> return_values {}
proc(args) -> return_values {}

proc where expression {}
proc(args) where expression {}
proc -> return_values where expression {}
proc(args) -> return_values where expression {}

// args are a comma separated list of single type and value variable declarations

// procedure declaration
proc ---
proc(args) ---
proc -> return_values ---
proc(args) -> return_values ---

proc where expression ---
proc(args) where expression ---
proc -> return_values where expression ---
proc(args) -> return_values where expression ---

// structs type
struct {}
struct(args) {}

// struct type declaration
struct ---

struct(args) ---

// union type
union {}
union(args) {}

// union type declaration
union ---
union(args) ---

// enums type
enum member_type {}

// enum typ declaration
enum member_type ---

// imports
import "path";
import "path" as name;

using import "path";

// include
include "path";

// foreign import
foreign import "path";
foreign import "path" as alias;

using import "path";
using import "path" as name;

// using
using expression;

// if
if expression do statement
if init; expression do statement
if expression {}
if init; expression {}

// when
when expression do statement
when init; expression do statement
when expression {}
when init; expression {}

// else (follows directly after an if or when)
else do statement
else {}

// while
while condition do statement
while init; condition do statement
while init; condition; step do statement

while condition {}
while init; condition {}
while init; condition; step {}

// break
break;
break expression;

// continue
continue;
continue expression;

// return
return;

return expression;
return expression0, expression1;

return name = expression;
return name0 = expression0, name1 = expression1;

// assignment
¤ is any binary op

name = expression;
name ¤= expression;

name0, name1 = expression;
name0, name1 ¤= expression;

name0, name1 = expression0, expression1;
name0, name1 ¤= expression, expression1;

// struct literals
{} // Ambiguity at statement level and allows "if {} {}"
{type: args} // Ambiguity at statement level

// array literals
[]
[expression]
[expression0, expression1]

[type:]
[type: expression]
[type: expression0, expression1]

// slice - maybe add [e0:e1:e2] for step?
name[:]
name[expression:]
name[:expression]
name[expression0:expression1]

// spread
..expression

// types
^            - pointer
[]           - slice
[expression] - array
[..]         - dynamic array

// for
/* to be added later
for symbol in expression do statement
for symbol0, symbol1 in expression do statement

for symbol in expression {}
for symbol0, symbol1 in expression {}
*/

// to be decide tomorrow
Should using support exceptions? Like use Math except Sin?
How should types work? Should types be more fancy?
How to make metaprograms work with libraries?
What about local constant declarations?
What about polymorphic declarations?
Operator overloading?
Context & dynamic arrays?

// decided
* Operator overloading and macros need to be thought through more thoroughly, but should be a part of the language.
  It shouldn't be a problem to add them later down the line
* Exceptions to using is a another thing that can easily be added later down the line, so it is wise to delay the
  decision.
* Polymorhpic declarations are passed down the pipeline as "templates" at first, and then every instantiation is passed,
  when they are instantiated.
CONTEXT SYSTEM - custom calling convention, TLS is not reliable
TYPES - Odin style, but with some implicit casting and pointer arithmetic
PACKAGES AND MODULES, PARTICULARLY LINK NAME PREFIXES
METAPROGRAM LIBS

Procedure :: proc
{
	DoStuff :: proc do return 5;

	{
		f := DoStuff();
		 // a lot of code

		DoStuff :: proc do return 5;
	}

	a : f64;

	^u64(a)
	(^u64)(a)
	(^u64)a // could pass parser, but checked by sema to ensure it is a cast

	(SQRT)5 == SQRT(5)

	e : ^Entity = &entity;

}


Types
Postulate that types are a description of the amount of memory and the layout and interpretation of that chunk of memory
E.g. a 32-bit int is a description of a chunk of memory that is 4 bytes long and should be interpreted as a contiguous set of
     bits that describe a signed binary integer of 32 bits. The layout/endianess is platform dependent.
1. What if rules surrounding access to the chunk of memory is also specified by the type? This could support atomic types, but
   is probably inferioir to explicitly calling procedures
2. What if the interpretation is dependent on some value? This is a union
3. What if the amount of memory used is depedent on some value? This is not possible with a staticly typed language
4. What if the layout is depedent on some value? This is just stupid
5. What if the layout is decided by the compiler? This is just struct field reordering
6. What about combining types? An "and" combination of types is just a struct, an "xor" combination is just a union
   "or" seems stupid, since then type is several things at once, and this just seems like a way of describing implicit
    casting
7. What about void? Should there be a type that decribes a chunk of memory that does not exist? Odin does not allow this and
   says that only "values" (essentially something that takes up memory) can have a type

void does not make sense by itself, unless talking about something that does not exist
void pointer seems like a pointer to something that does not exist, which is bizarre
void* in C is just a pointer to a generic block of memory with unspecified size
it is therefore better to use a generic pointer type (like Odin's rawptr) than pointer to void
this results in some problems with procedures that do not return a value, since what is their
return type then? I think it would make sense to say that they do not have a return type, since
they do not return anything. This would result in a type system like the one in Odin.

calling conventions
* default
* contextless
* ccall
* stdcall
* fastcall
* none
* odin?


include allows the inclusion of a single file's AST in the current one
includes do not deduplicate, as they embed AST

import is used to import a library
 * libraries must be easy to setup and well defined
 * it must be possible to allow a user to import only select parts of a library
 * libraries must have the ability to define their own metaprograms
 * a metaprogram may override the metaprogram of a library that it imports (subject to change)
 * libraries should have their own link name prefix (to avoid name collision)
 * library names should never collide
 * libraries have a public and private scope. The public scope is accessible from the importer, but
   the private is not. Import declarations are always private.

foreign import is used to import a foreign library

Should foreign include be a thing? Like include the converted AST of a compiled C header? This introduces a lot of problems due
to undefined behaviour in C, but it could prove usefull when, for example dealing with foreign library bindings. Maybe C files
could be included and associated with a foreign import, to automatically generate all procedure declarations and import them
from the dynamic library. This is sort of funky, so it should be thought over more before deciding to go either way.

how libraries work need to be decided another time
for the time being, just support AST include



HEY! LISTEN! guh~
There seems to be a lot of value in giving the metaprogram a semantically valid declaration with symbol info generated, but not
type checked. This allows the metaprogram to add swizzeling, custom implicit casting rules, allowing access of struct member fields by number instead of name, reorder structs for optimal packing, and much more.

It also seems like the split between the compiler internal representation and the metaprogram representation of the AST, and
a message loop to allow future expansion (in Jai) is useful

New mental model
The metaprogram works as an administrator, inspecting the actions of the compiler, able to change declarations that finish a
stage, push them back through that stage and allow declarations to flow into later stages

--> push to next stage
==> go through same stage again

..........          ..............................................          .................        ............
| Parser |-| |----> | Semantic Analysis & Symbol Info Generation |-| |----> | Type Checking |-| |--> | Code Gen |
.......... | |  ^   .............................................. | |  ^   ................. | |    ............
            M   |================================================== M   |===================== M
                ^                                                                            |
                |============================================================================|


// NOTE:
// compilation = program + packages
// when you add loose source files, they are treated as part of the program
// when a declaration is passed to the "next" stage, it cannot be "recycled"

// TODO: What about errors?
// they could be issued by a message to the metaprogram
// Should the compilation be recoverable?
// if a file does not exist, should the metaprogram be able to discard it and continue?
// but: max one parse error per file

// TODO: What about stalling?
// should there be a special message for when the compiler cannot resolve more types?
// this happens when the compiler encounteres a symbol that does not exist, which could
// be fixed by the metaprogram.
// e.g. the program requires a procedure named PrintEntity which is generated by the metaprogram. When should
//      the metaprogram generate this? It does not necessarily know when it has processed all the entities.
//      Is it easier to just wait on a stall and add it then? Or should the metaprogram add a declaration
//      up front for declarations that it does not know when will be generated?
// I think it is a reasonable requirement to force the user to declare those kinds of procedures before they
// are generated. Then, this kind of elimintates the use of a pipeline stall message.

// initialize compiler state
// free resources
// build binary

/// add to program
// add file
// add declaration
/// add to package
// add declaration to a certain package

// begin intercept

// wait for next message
/// if nothing is done before issuing a call to "wait for next message",
/// it is assumed that the user does not want do anything with the subject
/// of the message

/// file load intercept
// modify text and pass on

/// parse result intercept
// modify parsed ast and pass on

/// type checked intercept
// (optionally) modify and recirculate ast

// end intercept